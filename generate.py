import hydra
from omegaconf import DictConfig
import torch
from miditok import REMI, TokenizerConfig
from pathlib import Path
import os
import json
from src.model_module import MidiGenModule # Lightning Module ë¶ˆëŸ¬ì˜¤ê¸°

@hydra.main(version_base=None, config_path="configs", config_name="config")
def main(cfg: DictConfig):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"=== Midigen Lightning ì‘ê³¡ ì‹œì‘ (Device: {device}) ===")

    # 1. ì‘ê³¡ê°€ ë§¤í•‘ ì •ë³´ ë¡œë“œ
    if not os.path.exists("composer_map.json"):
        print("!! composer_map.jsonì´ ì—†ìŠµë‹ˆë‹¤. ëœë¤ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        composer_token_id = 0
        target_composer = "Unknown"
    else:
        with open("composer_map.json", "r") as f:
            mapping_info = json.load(f)
        composer_to_id = mapping_info["composer_to_id"]
        base_vocab_size = mapping_info["base_vocab_size"]
        
        target_composer = "FrÃ©dÃ©ric Chopin" 
        if target_composer not in composer_to_id:
            target_composer = list(composer_to_id.keys())[0]
        
        composer_token_id = base_vocab_size + composer_to_id[target_composer]
        print(f">> ì„ íƒëœ ì‘ê³¡ê°€: {target_composer} (ID: {composer_token_id})")

    # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ (í‘œì¤€ REMI)
    beat_res_dict = eval(cfg.data.beat_res) if isinstance(cfg.data.beat_res, str) else cfg.data.beat_res
    tokenizer_config = TokenizerConfig(
        num_velocities=cfg.data.num_velocities, 
        use_chords=True,
        use_tempos=True,
        beat_res=beat_res_dict
    )
    tokenizer = REMI(tokenizer_config)

    # 3. ëª¨ë¸ ë¡œë“œ (Lightningì˜ ë§ˆë²•!)
    # checkpoints í´ë”ì—ì„œ ê°€ì¥ ìµœì‹  .ckpt íŒŒì¼ì„ ì°¾ìŒ
    ckpts = sorted(Path("checkpoints").glob("*.ckpt"), key=os.path.getmtime)
    if not ckpts:
        print("!! ì²´í¬í¬ì¸íŠ¸(.ckpt)ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € train.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    ckpt_path = str(ckpts[-1])
    print(f">> ë¡œë“œ ì¤‘: {ckpt_path}")

    # ëª¨ë¸ êµ¬ì¡° + ê°€ì¤‘ì¹˜ ìë™ ë³µêµ¬
    model_module = MidiGenModule.load_from_checkpoint(ckpt_path, cfg=cfg)
    model_module.to(device)
    model_module.eval()
    
    # ì‹¤ì œ GPT-2 ëª¨ë¸ êº¼ë‚´ê¸°
    model = model_module.model 

    # 4. ìƒì„± ì‹œì‘
    # ì‹œë“œ: [ì‘ê³¡ê°€, Bar]
    seed_ids = [composer_token_id, tokenizer["Bar_None"]]
    print(f">> ì‹œë“œ: {seed_ids}")

    print(">> ì‘ê³¡ ì¤‘...")
    with torch.no_grad():
        generated_ids = model.generate(
            input_ids=torch.tensor([seed_ids]).to(device),
            max_length=1024,
            do_sample=True,
            temperature=0.9,       # ì°½ì˜ì„±
            top_k=20,              # ì•ˆì •ì„±
            repetition_penalty=1.0,
            pad_token_id=0
        )

    # 5. ì €ì¥
    gen_token_ids = generated_ids[0].cpu().numpy().tolist()
    final_midi_ids = [t for t in gen_token_ids if t < len(tokenizer)]
    
    generated_midi = tokenizer.decode([final_midi_ids])
    save_path = f"output_{target_composer.replace(' ', '_')}.mid"
    generated_midi.dump_midi(save_path)
    print(f"\n=== ğŸ¹ ì‘ê³¡ ì™„ë£Œ! ì €ì¥ë¨: {save_path} ===")

if __name__ == "__main__":
    main()