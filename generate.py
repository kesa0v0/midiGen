import hydra
from omegaconf import DictConfig
import torch
from miditok import REMI, TokenizerConfig
from pathlib import Path
import os
import json
from src.models import MidigenTitans
from collections import Counter
from transformers import GPT2Config, GPT2LMHeadModel, LogitsProcessor, LogitsProcessorList

# [í•µì‹¬] ë‹¨ì–´ì¥ í¬ê¸°ë¥¼ ë²—ì–´ë‚˜ëŠ” ìƒì„±ì„ ë§‰ëŠ” ì œí•œ ì¥ì¹˜
class RestrictVocabLogitsProcessor(LogitsProcessor):
    def __init__(self, actual_vocab_size):
        self.actual_vocab_size = actual_vocab_size

    def __call__(self, input_ids, scores):
        # ë‹¨ì–´ì¥ í¬ê¸°(actual_vocab_size) ì´ìƒì˜ í† í° ì ìˆ˜ë¥¼ -Infinityë¡œ ë§Œë“¤ì–´ ì„ íƒ ì•ˆ ë˜ê²Œ í•¨
        # ì˜ˆ: ëª¨ë¸ì€ 10000ê°œê¹Œì§€ ì•Œì§€ë§Œ, ì‹¤ì œ ë‹¨ì–´ëŠ” 5000ê°œë¼ë©´ 5000ë²ˆ ì´í›„ëŠ” ì ˆëŒ€ ì•ˆ ë½‘ìŒ
        vocab_size = scores.shape[-1]
        if self.actual_vocab_size < vocab_size:
            scores[:, self.actual_vocab_size:] = -float('inf')
        return scores

@hydra.main(version_base=None, config_path="configs", config_name="config")
def main(cfg: DictConfig):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"=== Midigen V3 [Final Generation] ì‘ê³¡ ì‹œì‘ (Device: {device}) ===")

    # 1. ë§¤í•‘ ì •ë³´ ë¡œë“œ
    if not os.path.exists("composer_map.json"):
        raise FileNotFoundError("composer_map.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with open("composer_map.json", "r") as f:
        mapping_info = json.load(f)
    
    composer_to_id = mapping_info["composer_to_id"]
    base_vocab_size = mapping_info["base_vocab_size"] # BPE í¬ê¸° (ì˜ˆ: 5000)
    
    # ì‘ê³¡ê°€ ì„ íƒ
    target_composer = "FrÃ©dÃ©ric Chopin" 
    if target_composer not in composer_to_id:
        target_composer = list(composer_to_id.keys())[0]

    # ì‘ê³¡ê°€ í† í° ID ê³„ì‚°
    composer_token_id = base_vocab_size + composer_to_id[target_composer]
    print(f">> ì„ íƒëœ ì‘ê³¡ê°€: {target_composer} (Token ID: {composer_token_id})")

    # # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ (tokenizer.json í•„ìˆ˜)
    # if os.path.exists("tokenizer.json"):
    #     print(">> í•™ìŠµëœ BPE í† í¬ë‚˜ì´ì €(tokenizer.json)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
    #     tokenizer = REMI(params="tokenizer.json")
    # else:
    #     print("!! ê²½ê³ : tokenizer.jsonì´ ì—†ìŠµë‹ˆë‹¤. ì—‰ëš±í•œ ìŒì•…ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    tokenizer_config = TokenizerConfig(
        num_velocities=cfg.data.num_velocities, 
        use_chords=cfg.data.use_chords,
        beat_res=eval(cfg.data.beat_res)
    )
    tokenizer = REMI(tokenizer_config)

    # 3. ëª¨ë¸ ë¡œë“œ (GPT-2)
    print(f">> Model Type: {cfg.model.type}")
    if cfg.model.type == "gpt2":
        model_config = GPT2Config(
            vocab_size=cfg.data.vocab_size, # configì˜ 10000
            n_positions=cfg.data.max_seq_len,
            n_embd=cfg.model.dim,
            n_layer=cfg.model.depth,
            n_head=cfg.model.heads,
            pad_token_id=0
        )
        model = GPT2LMHeadModel(model_config).to(device)
    else:
        model = MidigenTitans(cfg).to(device)

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    ckpts = sorted(Path("checkpoints").glob("*.pt"), key=os.path.getmtime)
    if not ckpts:
        print("!! ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ")
        return
    ckpt_path = str(ckpts[-1])
    print(f">> ë¡œë“œ ì¤‘: {ckpt_path}")
    
    model.load_state_dict(torch.load(ckpt_path, map_location=device, weights_only=True))
    model.eval()

    # 4. ì‹œë“œ(Seed) ì¤€ë¹„: [ì‘ê³¡ê°€] + [Bar]
    # BPE ëª¨ë¸ì€ 'NoteOn' í•˜ë‚˜ë§Œ ì£¼ë©´ í—·ê°ˆë ¤í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 
    # ê·¸ëƒ¥ ì‘ê³¡ê°€ë‘ ì‹œì‘ ì‹ í˜¸ë§Œ ì£¼ê³  ì•Œì•„ì„œ í•˜ë¼ê³  í•˜ëŠ” ê²Œ ë‚«ìŠµë‹ˆë‹¤.
    seed_ids = [composer_token_id, tokenizer["Bar_None"]] 
    print(f">> ì‹œë“œ êµ¬ì„±: [Composer: {target_composer}] + [Bar_None]")

    # 5. ìƒì„± (LogitsProcessor ì ìš©)
    actual_vocab_size = len(tokenizer)
    print(f">> í† í¬ë‚˜ì´ì € ì‹¤ì œ í¬ê¸°: {actual_vocab_size} (ì´ë³´ë‹¤ í° IDëŠ” ì°¨ë‹¨í•©ë‹ˆë‹¤)")
    
    # logits_processor = LogitsProcessorList([
    #     RestrictVocabLogitsProcessor(actual_vocab_size)
    # ])

    print(">> ì‘ê³¡ ì¤‘...")
    with torch.no_grad():
        generated_ids = model.generate(
            input_ids=torch.tensor([seed_ids]).to(device),
            max_length=1024,
            do_sample=True,
            temperature=0.8,       # 0.8: ë„ˆë¬´ ëœë¤í•˜ì§€ ì•Šê²Œ (Position í­ì£¼ ë°©ì§€)
            top_k=20,              
            repetition_penalty=1.0, # [ì¤‘ìš”] 1.0 = í˜ë„í‹° ë”. ìŒì•…ì€ ë°˜ë³µì´ ìƒëª…ì…ë‹ˆë‹¤.
            pad_token_id=0,
            # logits_processor=logits_processor # ì œí•œ ì¥ì¹˜ ì¥ì°©
        )

    # 6. ì €ì¥ ë° ê²°ê³¼ ë¶„ì„
    gen_token_ids = generated_ids[0].cpu().numpy().tolist()

    # í†µê³„ ê³„ì‚°
    decoded_tokens = []
    valid_ids_for_midi = []
    
    # ì‘ê³¡ê°€ í† í°(seedì— í¬í•¨ë¨)ì€ í†µê³„ì—ì„œ ì œì™¸í•˜ê³  ìƒì„±ëœ ê²ƒë§Œ ë¶„ì„
    generated_part = gen_token_ids[len(seed_ids):]

    print(f">> ìƒì„±ëœ í† í° í•´ë… ì¤‘... (ì´ {len(generated_part)}ê°œ)")

    for tid in generated_part:
        # 1. ë²”ìœ„ ì²´í¬
        if tid >= len(tokenizer):
            continue
            
        # 2. ì¡´ì¬ ì—¬ë¶€ ì²´í¬ (KeyError ë°©ì§€)
        try:
            # tokenizer[tid]ê°€ ì‹¤íŒ¨í•˜ë©´ exceptë¡œ ë„˜ì–´ê°
            token_str = tokenizer[tid] 
            decoded_tokens.append(token_str)
            valid_ids_for_midi.append(tid)
        except KeyError:
            # 325ë²ˆ ê°™ì€ ìœ ë ¹ í† í°ì€ ë¬´ì‹œ
            continue
        except Exception as e:
            print(f"!! í† í° í•´ë… ì¤‘ ì˜ˆì™¸ ë°œìƒ (ID: {tid}): {e}")
            continue
    
    counts = Counter([t.split('_')[0] for t in decoded_tokens if isinstance(t, str)])
    
    print("\n=== ìƒì„± ê²°ê³¼ í†µê³„ ===")
    print(f"ì´ ìƒì„± ê¸¸ì´: {len(generated_part)}")
    print(f"ìœ íš¨í•œ í† í°: {len(valid_ids_for_midi)}")
    print(f"ğŸµ ìŒí‘œ(Pitch/NoteOn): {counts.get('Pitch', 0) + counts.get('NoteOn', 0)}")
    print(f"â³ ì‹œê°„(Position): {counts.get('Position', 0)}")
    print(f"ğŸ¹ í™”ìŒ/ê¸°íƒ€(Chord ë“±): {counts.get('Chord', 0)}")
    
    # MIDI ë³€í™˜ (ì‘ê³¡ê°€ í† í° ì œì™¸í•˜ê³  ìˆœìˆ˜ ìŒì•… í† í°ë§Œ)
    # ì‹œë“œì— ìˆë˜ Bar_Noneì€ í¬í•¨í•´ë„ ë¨
    if "Bar_None" in tokenizer.vocab:
        start_token = tokenizer["Bar_None"]
    else:
        # í˜¹ì‹œ Bar_Noneë„ ì—†ìœ¼ë©´ 0ë²ˆì´ë‚˜ ê°€ì¥ ìì£¼ ë‚˜ì˜¤ëŠ” í† í°ìœ¼ë¡œ ëŒ€ì²´ (ì•ˆì „ì¥ì¹˜)
        start_token = valid_ids_for_midi[0] if valid_ids_for_midi else 0

    final_midi_ids = [start_token] + valid_ids_for_midi
    
    if len(valid_ids_for_midi) < 10:
        print("!! ê²½ê³ : ìƒì„±ëœ ìŒí‘œê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (ëŒ€ë¶€ë¶„ì´ ìœ ë ¹ í† í°ì´ê±°ë‚˜ ìƒì„± ì‹¤íŒ¨)")
    else:
        try:
            generated_midi = tokenizer.decode([final_midi_ids])
            save_path = f"output_{target_composer.replace(' ', '_')}.mid"
            generated_midi.dump_midi(save_path)
            print(f"\n=== ğŸ¹ ì‘ê³¡ ì™„ë£Œ! ì €ì¥ë¨: {save_path} ===")
            print("ì´ì œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì„œ ë“¤ì–´ë³´ì„¸ìš”!")
        except Exception as e:
            print(f"MIDI ë³€í™˜ ì—ëŸ¬: {e}")
            print("íŒ: í† í¬ë‚˜ì´ì € ì„¤ì •(Beat Resolution ë“±)ì´ í•™ìŠµ ë•Œì™€ ë‹¤ë¥¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()