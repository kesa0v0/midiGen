# configs/config.yaml

project_name: "midigen_v4_anticipation_titan"

defaults:
  - _self_

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

data:
  # 데이터 경로 (상대 경로 주의)
  raw_path: "${hydra:runtime.cwd}/data/raw/maestro-v3.0.0"
  csv_path: "${hydra:runtime.cwd}/data/raw/maestro-v3.0.0/maestro-v3.0.0.csv"
  processed_path: "${hydra:runtime.cwd}/data/processed/maestro_tokenized"

tokenizer:
  name: anticipation # remi or anticipation
  max_seq_len: 2048 # Reduced from 2048 to mitigate large vocab overhead
  remi:
    beat_res: "{(0, 4): 8, (4, 12): 4}" # Beat resolution for miditok
    nb_velocities: 24 # Number of velocity bins, renamed from num_velocities
    use_chords: true
    use_rests: False # Defaulting to false, was not in original config
    use_programs: False # Defaulting to false, was not in original config
    use_tempos: False # Defaulting to false, was not in original config
    use_time_signatures: False # Defaulting to false, was not in original config
    rest_range: "[2, 8]" # Defaulting to common range
    tempo_range: "[50, 200]" # Defaulting to common range
    use_program_changes: False # Defaulting to false
  anticipation:
    bar_token_id: 50 # Default bar token ID for anticipation tokenizer.

model:
  type: "titan"  # "gpt2" 또는 "titan"
  dim: 256
  depth: 8
  heads: 4

train:
  batch_size: 2 # 8 -> 4 -> 2 (for VRAM OOM fix)
  accumulate_grad_batches: 4 # 4 * 2 = 8 -> 2 * 4 = 8 (Effective Batch Size maintained)
  epochs: 50
  lr: 3e-4
  force_preprocess: true # true to regenerate data with new seq_len
  resume_ckpt_path: "auto"  # "auto"면 최신 체크포인트, 비우면 처음부터

compile_model: false

target_composer: "Claude Debussy"
target_length: 10240  # 생성할 최대 토큰 길이